

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Searching &mdash; The Spiritualist 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=f2a433a1"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Article Extraction" href="article_extraction.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            The Spiritualist
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">The Spiritualist</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">About dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="newspapers.html">Newspapers and and its layout</a></li>
<li class="toctree-l1"><a class="reference internal" href="paper_extraction.html">Text Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="article_extraction.html">Article Extraction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Searching</a><ul class="simple">
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">The Spiritualist</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Searching</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/vector_database.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="searching">
<h1>Searching<a class="headerlink" href="#searching" title="Link to this heading"></a></h1>
<p><strong>Elasticsearch</strong></p>
<p>In this project, Elasticsearch serves as the vector database responsible for storing and retrieving
semantically meaningful representations (embeddings) of the documents in our corpus.
These vector embeddings enable fast and scalable similarity search, which is a core component of
the Retrieval-Augmented Generation (RAG) pipeline.</p>
<p><strong>Why Elasticsearch?</strong></p>
<p>Elasticsearch is traditionally known for keyword-based search using inverted indices. However,
recent versions (7.3+) support dense vector fields and approximate nearest neighbor (ANN)
search using methods like HNSW (Hierarchical Navigable Small World graphs), which makes it suitable
for semantic search in NLP/LLM applications.</p>
<p><strong>Configuration and Setup</strong></p>
<p>Embedding Generation:</p>
<p>Documents are first embedded using MPNet (via sentence-transformers).
Each document is converted into a fixed-size dense vector (typically 768 dimensions).</p>
<p>Index Creation in Elasticsearch:</p>
<p>The index is configured with a dense_vector field to store embeddings.
HNSW is enabled for efficient ANN search.</p>
<p>Following code shows the mapping for the indexing of the vector database.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span> <span class="k">def</span><span class="w"> </span><span class="nf">create_index</span><span class="p">():</span>
<span class="linenos"> 2</span>     <span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos"> 3</span>         <span class="s2">&quot;mappings&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos"> 4</span>             <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos"> 5</span>                 <span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;keyword&quot;</span><span class="p">},</span>
<span class="linenos"> 6</span>                 <span class="s2">&quot;page_number&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;keyword&quot;</span><span class="p">},</span>
<span class="linenos"> 7</span>                 <span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">},</span>
<span class="linenos"> 8</span>                 <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">},</span>
<span class="linenos"> 9</span>                 <span class="s2">&quot;text_embedding&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">10</span>                     <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;dense_vector&quot;</span><span class="p">,</span>
<span class="linenos">11</span>                     <span class="s2">&quot;dims&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span>  <span class="c1"># &lt;- MPNet output size</span>
<span class="linenos">12</span>                     <span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<span class="linenos">13</span>                     <span class="s2">&quot;similarity&quot;</span><span class="p">:</span> <span class="s2">&quot;cosine&quot;</span>
<span class="linenos">14</span>                 <span class="p">}</span>
<span class="linenos">15</span>             <span class="p">}</span>
<span class="linenos">16</span>         <span class="p">}</span>
<span class="linenos">17</span>     <span class="p">}</span>
</pre></div>
</div>
<p>Ingestion:
Each document is ingested along with its embedding. Metadata (e.g., title, source) can also be included to enrich filtering.</p>
<p><strong>Querying</strong></p>
<p>The user input is embedded using the same MPNet model. A vector similarity search is performed against the embedding field in Elasticsearch.
The top-k most similar documents are returned, ranked by cosine similarity.</p>
<p>Following code shows the sample quering.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span> <span class="n">dense_query</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos"> 2</span>     <span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="n">top_k</span><span class="p">,</span> <span class="c1"># This was set to 5</span>
<span class="linenos"> 3</span>     <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos"> 4</span>         <span class="s2">&quot;script_score&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos"> 5</span>             <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;match_all&quot;</span><span class="p">:</span> <span class="p">{}},</span>
<span class="linenos"> 6</span>             <span class="s2">&quot;script&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos"> 7</span>                 <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;cosineSimilarity(params.query_vector, &#39;text_embedding&#39;) + 1.0&quot;</span><span class="p">,</span>
<span class="linenos"> 8</span>                 <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;query_vector&quot;</span><span class="p">:</span> <span class="n">query_vec</span><span class="p">}</span>
<span class="linenos"> 9</span>             <span class="p">}</span>
<span class="linenos">10</span>         <span class="p">}</span>
<span class="linenos">11</span>     <span class="p">}</span>
<span class="linenos">12</span> <span class="p">}</span>
</pre></div>
</div>
<p><strong>Performance Considerations</strong></p>
<p>HNSW greatly improves the speed of similarity search compared to brute-force.
Vector indexing can increase memory usage — tune m, ef_construction, and shard settings appropriately.
Inference time is impacted by both embedding generation and retrieval latency — caching common queries can improve responsiveness.</p>
<div class="toctree-wrapper compound">
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="article_extraction.html" class="btn btn-neutral float-left" title="Article Extraction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Dr.Rosa Filgueira, Virag Umathe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>